# -*- coding: utf-8 -*-
"""Distracted_Driving_Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Pcud1liNVsb9o2-eOBauQ_1HoQB9jqto
"""

!pwd

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os

# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,
# your files will be saved in your Google Drive!

# the base Google Drive directory
root_dir = "/content/drive/MyDrive/"

# choose where you want your project files to be saved
project_folder = "Major Project"

def create_and_set_working_directory(project_folder):
  # check if your project folder exists. if not, it will be created.
  if os.path.isdir(root_dir + project_folder) == False:
    os.mkdir(root_dir + project_folder)
    print(root_dir + project_folder + ' did not exist but was created.')

  # change the OS to use your project folder as the working directory
  os.chdir(root_dir + project_folder)

  # create a test file to make sure it shows up in the right place
  # !touch 'new_file_in_working_directory.txt'
  print('\nYour working directory was changed to ' + root_dir + project_folder + \
        "\n\nAn empty text file was created there. You can also run !pwd to confirm the current working directory." )

create_and_set_working_directory(project_folder)

!pwd

os.environ['KAGGLE_USERNAME'] = "vedanthr" # username from the json file
os.environ['KAGGLE_KEY'] = "f54bc7643b23975c0ff08e4ba567f796" # key from the json file

!kaggle datasets download -d vedanthr/distracted-driver-custom

!unzip "/content/drive/MyDrive/Major Project/distracted-driver-custom.zip" -d "/content/drive/MyDrive/Major Project/distracted_drivers_dataset"

import tensorflow as tf

av_model = tf.keras.model.load_model("augmented_vanilla_cnn.h5")

# Commented out IPython magic to ensure Python compatibility.
import os
from glob import glob
import random
import time
import tensorflow
import datetime
os.environ['KERAS_BACKEND'] = 'tensorflow'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 3 = INFO, WARNING, and ERROR messages are not printed

from tqdm import tqdm

import numpy as np
import pandas as pd
from IPython.display import FileLink
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
import seaborn as sns
# %matplotlib inline
from IPython.display import display, Image
import matplotlib.image as mpimg
import cv2

from sklearn.model_selection import train_test_split
from sklearn.datasets import load_files
from keras.utils import np_utils
from sklearn.utils import shuffle
from sklearn.metrics import log_loss

from keras.models import Sequential, Model
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing import image
from keras.callbacks import ModelCheckpoint, EarlyStopping
from keras.applications.vgg16 import VGG16

import pandas as pd
dataset = pd.read_csv('/content/drive/MyDrive/Major Project/distracted_drivers_dataset/driver_imgs_list.csv')
dataset.head()

by_drivers = dataset.groupby('subject')
unique_drivers = by_drivers.groups.keys()
print(unique_drivers)

# Load the dataset previously downloaded from Kaggle
NUMBER_CLASSES = 10
# Color type: 1 - grey, 3 - rgb

def get_cv2_image(path, img_rows, img_cols, color_type=3):
    # Loading as Grayscale image
    if color_type == 1:
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    elif color_type == 3:
        img = cv2.imread(path, cv2.IMREAD_COLOR)
    # Reduce size
    img = cv2.resize(img, (img_rows, img_cols))
    return img

# Training
# In mounted Google drive
# /content/drive/MyDrive/Major Project/distracted_drivers_dataset/imgs/train/c0
def load_train(img_rows, img_cols, color_type=3):
    start_time = time.time()
    train_images = []
    train_labels = []
    # Loop over the training folder
    for classed in tqdm(range(NUMBER_CLASSES)):
        print('Loading directory c{}'.format(classed))
        files = glob(os.path.join('/content', 'drive', 'MyDrive', 'Major Project', 'distracted_drivers_dataset', 'imgs', 'train', 'c' + str(classed), '*.jpg'))
        for file in files:
            img = get_cv2_image(file, img_rows, img_cols, color_type)
            train_images.append(img)
            train_labels.append(classed)
        print(len(files),"**")
    print("Data Loaded in {} second".format(time.time() - start_time))
    return train_images, train_labels

print(os.path.join('content', 'drive', 'MyDrive', 'Major Project', 'distracted_drivers_dataset', 'imgs', 'train', 'c' + '0', '*.jpg'))

def read_and_normalize_train_data(img_rows, img_cols, color_type):
    X, labels = load_train(img_rows, img_cols, color_type)
    y = np_utils.to_categorical(labels, 10)
    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    x_train = np.array(x_train, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)
    x_test = np.array(x_test, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)

    return x_train, x_test, y_train, y_test

# Testing
# In mounted Google drive
# /content/drive/MyDrive/Major Project/distracted_drivers_dataset/imgs/test/c0
def load_test(img_rows, img_cols, color_type=3):
    start_time = time.time()
    test_images = []
    test_labels = []
    # Loop over the testing folder
    for classed in tqdm(range(NUMBER_CLASSES)):
        print('Loading directory c{}'.format(classed))
        files = glob(os.path.join('/content', 'drive', 'MyDrive', 'Major Project', 'distracted_drivers_dataset', 'imgs', 'test', 'c' + str(classed), '*.jpg'))
        for file in files:
            img = get_cv2_image(file, img_rows, img_cols, color_type)
            test_images.append(img)
            test_labels.append(classed)
        # print(len(files),"**")
    print("Data Loaded in {} second".format(time.time() - start_time))
    return test_images, test_labels


def read_and_normalize_test_data(img_rows, img_cols, color_type):
    X_test_new, labels = load_test(img_rows, img_cols, color_type)
    y_test_new = np_utils.to_categorical(labels, 10)
    X_test_new = np.array(X_test_new, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)
    return X_test_new, y_test_new

img_rows = 64
img_cols = 64
color_type = 1

"""Should be 19924 train-validate images and 2500 test images"""

x_train, x_test, y_train, y_test = read_and_normalize_train_data(img_rows, img_cols, color_type)
print('Train shape:', x_train.shape)
print(x_train.shape[0], 'train samples')

x_test_new, y_test_new = read_and_normalize_test_data(img_rows, img_cols, color_type)
print('Test shape:', x_test_new.shape)
print(x_test_new.shape[0], 'test samples')

# Plot figure size
plt.figure(figsize = (10,10))
# Count the number of images per category
sns.countplot(x = 'classname', data = dataset)
# Change the Axis names
plt.ylabel('Count')
plt.title('Categories Distribution')
# Show plot
plt.show()

# Find the frequency of images per driver
drivers_id = pd.DataFrame((dataset['subject'].value_counts()).reset_index())
drivers_id.columns = ['driver_id', 'Counts']
drivers_id

# Plotting class distribution
dataset['class_type'] = dataset['classname'].str.extract('(\d)',expand=False).astype(np.float)
plt.figure(figsize = (20,20))
dataset.hist('class_type', alpha=0.5, layout=(1,1), bins=10)
plt.title('Class distribution')
plt.show()

activity_map = {'c0': 'Safe driving',
                'c1': 'Texting - right',
                'c2': 'Talking on the phone - right',
                'c3': 'Texting - left',
                'c4': 'Talking on the phone - left',
                'c5': 'Operating the radio',
                'c6': 'Drinking',
                'c7': 'Reaching behind',
                'c8': 'Hair and makeup',
                'c9': 'Talking to passenger'}

plt.figure(figsize = (12, 20))
image_count = 1
BASE_URL = '/content/drive/MyDrive/Major Project/distracted_drivers_dataset/imgs/train/'
for directory in os.listdir(BASE_URL):
    if directory[0] != '.':
        for i, file in enumerate(os.listdir(BASE_URL + directory)):
            if i == 1:
                break
            else:
                fig = plt.subplot(5, 2, image_count)
                image_count += 1
                image = mpimg.imread(BASE_URL + directory + '/' + file)
                plt.imshow(image)
                plt.title(activity_map[directory])

batch_size = 40
nb_epoch = 30

checkpointer = ModelCheckpoint(filepath='saved_models/weights_best_vanilla.hdf5',
                               monitor='val_loss', mode='min',
                               verbose=1, save_best_only=True)
es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=2)
callbacks = [checkpointer, es]

"""**Optimised Vanilla CNN Model**"""

def create_model_v2():
    # Optimised Vanilla CNN model
    model = Sequential()

    ## CNN 1
    model.add(Conv2D(32,(3,3),activation='relu',input_shape=(img_rows, img_cols, color_type)))
    model.add(BatchNormalization())
    model.add(Conv2D(32,(3,3),activation='relu',padding='same'))
    model.add(BatchNormalization(axis = 3))
    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))
    model.add(Dropout(0.3))

    ## CNN 2
    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))
    model.add(BatchNormalization())
    model.add(Conv2D(64,(3,3),activation='relu',padding='same'))
    model.add(BatchNormalization(axis = 3))
    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))
    model.add(Dropout(0.3))

    ## CNN 3
    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))
    model.add(BatchNormalization())
    model.add(Conv2D(128,(3,3),activation='relu',padding='same'))
    model.add(BatchNormalization(axis = 3))
    model.add(MaxPooling2D(pool_size=(2,2),padding='same'))
    model.add(Dropout(0.5))

    ## Output
    model.add(Flatten())
    model.add(Dense(512,activation='relu'))
    model.add(BatchNormalization())
    model.add(Dropout(0.5))
    model.add(Dense(128,activation='relu'))
    model.add(Dropout(0.25))
    model.add(Dense(10,activation='softmax'))

    return model

model_v2 = create_model_v2()

# More details about the layers
model_v2.summary()

# Compiling the model
model_v2.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

history_v2 = model_v2.fit(x_train, y_train,
          validation_data=(x_test, y_test),
          callbacks=callbacks,
          epochs=nb_epoch, batch_size=batch_size, verbose=1)

def plot_train_history(history):
    # Summarize history for accuracy
    plt.plot(history.history['accuracy'])
    plt.plot(history.history['val_accuracy'])
    plt.title('Model accuracy')
    plt.ylabel('accuracy')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()

    # Summarize history for loss
    plt.plot(history.history['loss'])
    plt.plot(history.history['val_loss'])
    plt.title('Model loss')
    plt.ylabel('loss')
    plt.xlabel('epoch')
    plt.legend(['train', 'test'], loc='upper left')
    plt.show()

plot_train_history(history_v2)

print(history_v2.history.keys())

score = model_v2.evaluate(x_test_new, y_test_new, verbose=1)
print('Score: ', score)

y_pred = model_v2.predict(x_test_new, batch_size=batch_size, verbose=1)
score = log_loss(y_test_new, y_pred)
print('Score log loss:', score)

model_v2.save("opt_vanilla_cnn_10epo.h5")

"""## Train a CNN with Transfer Learning (VGG, MobileNet)"""

def vgg_std16_model(img_rows, img_cols, color_type=3):
    nb_classes = 10
    # Remove fully connected layer and replace
    # with softmax for classifying 10 classes
    vgg16_model = VGG16(weights="imagenet", include_top=False)

    # Freeze all layers of the pre-trained model
    for layer in vgg16_model.layers:
        layer.trainable = False

    x = vgg16_model.output
    x = GlobalAveragePooling2D()(x)
    x = Dense(1024, activation='relu')(x)
    predictions = Dense(nb_classes, activation = 'softmax')(x)

    model = Model(inputs = vgg16_model.input, outputs = predictions)

    return model

# Load the VGG16 network
print("Loading network...")
model_vgg16 = vgg_std16_model(img_rows, img_cols)

model_vgg16.summary()

model_vgg16.compile(loss='categorical_crossentropy',
                         optimizer='rmsprop',
                         metrics=['accuracy'])

# Prepare data augmentation configuration
train_datagen = ImageDataGenerator(rescale = 1.0/255,
                                   shear_range = 0.2,
                                   zoom_range = 0.2,
                                   horizontal_flip = True,
                                   validation_split = 0.2)

test_datagen = ImageDataGenerator(rescale=1.0/ 255, validation_split = 0.2)

TRAIN_DIR = '/content/drive/MyDrive/Major Project/distracted_drivers_dataset/imgs/train/'
TEST_DIR = '/content/drive/MyDrive/Major Project/distracted_drivers_dataset/imgs/test/'

training_generator = train_datagen.flow_from_directory(TRAIN_DIR,
                                                 target_size = (img_rows, img_cols),
                                                 batch_size = batch_size,
                                                 shuffle=True,
                                                 class_mode='categorical', subset="training")

validation_generator = test_datagen.flow_from_directory(TRAIN_DIR,
                                                   target_size = (img_rows, img_cols),
                                                   batch_size = batch_size,
                                                   shuffle=False,
                                                   class_mode='categorical', subset="validation")
nb_train_samples = 15943
nb_validation_samples = 3981
print(validation_generator)

# Training the Vanilla Model
checkpoint = ModelCheckpoint('saved_models/weights_best_vgg16.hdf5', monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')
history_v4 = model_vgg16.fit_generator(training_generator,
                         steps_per_epoch = 15943 // batch_size,
                         epochs = 5,
                         callbacks=[es, checkpoint],
                         verbose = 1,
                        #  class_weight='auto')
                         validation_data = validation_generator,
                         validation_steps = 3981 // batch_size)

model_vgg16.save("vgg16_epo10.h5")

"""**Testing and demo of the model**"""

from google.colab import drive
drive.mount('/content/drive', force_remount=True)

import os

# Set your working directory to a folder in your Google Drive. This way, if your notebook times out,
# your files will be saved in your Google Drive!

# the base Google Drive directory
root_dir = "/content/drive/MyDrive/"

# choose where you want your project files to be saved
project_folder = "Major Project"

def create_and_set_working_directory(project_folder):
  # check if your project folder exists. if not, it will be created.
  if os.path.isdir(root_dir + project_folder) == False:
    os.mkdir(root_dir + project_folder)
    print(root_dir + project_folder + ' did not exist but was created.')

  # change the OS to use your project folder as the working directory
  os.chdir(root_dir + project_folder)

  # create a test file to make sure it shows up in the right place
  # !touch 'new_file_in_working_directory.txt'
  print('\nYour working directory was changed to ' + root_dir + project_folder + \
        "\n\nAn empty text file was created there. You can also run !pwd to confirm the current working directory." )

create_and_set_working_directory(project_folder)

!pwd

MODEL_PATH = '/content/drive/MyDrive/Major Project/opt_vanilla_cnn_30epo.h5'
TESTING_DATA_PATH = '/content/drive/MyDrive/Major Project/distracted_driver_dataset/imgs/test/'

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import os
from glob import glob
import random
import time
import tensorflow
import datetime
os.environ['KERAS_BACKEND'] = 'tensorflow'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # 3 = INFO, WARNING, and ERROR messages are not printed

from tqdm import tqdm

import numpy as np
import pandas as pd
from IPython.display import FileLink
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')
import seaborn as sns
# %matplotlib inline
from IPython.display import display, Image
import matplotlib.image as mpimg
import cv2

from sklearn.model_selection import train_test_split
from sklearn.datasets import load_files
from keras.utils import np_utils
from sklearn.utils import shuffle
from sklearn.metrics import log_loss

from keras.models import Sequential, Model
from keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization, GlobalAveragePooling2D
from keras.preprocessing.image import ImageDataGenerator
from keras.preprocessing import image
from keras.callbacks import ModelCheckpoint, EarlyStopping

def get_cv2_image(path, img_rows, img_cols, color_type=3):
    # Loading as Grayscale image
    if color_type == 1:
        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
    elif color_type == 3:
        img = cv2.imread(path, cv2.IMREAD_COLOR)
    # Reduce size
    img = cv2.resize(img, (img_rows, img_cols))
    return img

# Testing
# In mounted Google drive
# /content/drive/MyDrive/Major Project/distracted_drivers_dataset/imgs/test/c0
def load_test_demo(img_rows, img_cols, color_type=3):
    # start_time = time.time()
    test_images = []
    test_labels = []
    # Loop over the testing folder
    for classed in tqdm(range(NUMBER_CLASSES)):
        print('Loading directory c{}'.format(classed))
        files = glob(os.path.join('/content', 'drive', 'MyDrive', 'Major Project', 'distracted_drivers_dataset', 'imgs', 'test', 'c' + str(classed), '*.jpg'))
        i = 0
        for file in files:
            img = get_cv2_image(file, img_rows, img_cols, color_type)
            test_images.append(img)
            test_labels.append(classed)
            i=i+1
            if i==1:
              break
        # print(len(files),"**")
    # print("Data Loaded in {} second".format(time.time() - start_time))
    return test_images, test_labels


def read_and_normalize_test_data(img_rows, img_cols, color_type):
    X_test_new, labels = load_test_demo(img_rows, img_cols, color_type)
    y_test_new = np_utils.to_categorical(labels, 10)
    X_test_new = np.array(X_test_new, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)
    return X_test_new, y_test_new

img_rows = 64
img_cols = 64
color_type = 1
NUMBER_CLASSES = 10

x_test_new, y_test_new = read_and_normalize_test_data(img_rows, img_cols, color_type)
print('Test shape:', x_test_new.shape)
print(x_test_new.shape[0], 'test samples')

def load_test_img(img_rows, img_cols, color_type=3):
    # start_time = time.time()
    test_images = []
    test_labels = []
    # Loop over the testing folder
    for classed in tqdm(range(NUMBER_CLASSES)):
        print('Loading directory c{}'.format(classed))
        files = glob(os.path.join('/content', 'drive', 'MyDrive', 'Major Project', 'distracted_drivers_dataset', 'imgs', 'test', 'c' + str(classed), '*.jpg'))
        i = 0
        for file in files:
            img = cv2.imread(file)
            test_images.append(img)
            i=i+1
            if i==1:
              break
        # print(len(files),"**")
    # print("Data Loaded in {} second".format(time.time() - start_time))
    return test_images

from google.colab.patches import cv2_imshow
# test_imgs = load_test_demo(128,128,3)
# for i in test_imgs:
#   cv2_imshow(i)

activity_map = {'c0': 'Safe driving',
                'c1': 'Texting on the phone - left',
                'c2': 'Talking on the phone - right',
                'c3': 'Texting on the phone - right',
                'c4': 'Talking on the phone - left',
                'c5': 'Operating the radio',
                'c6': 'Drinking',
                'c7': 'Reaching behind',
                'c8': 'Hair and makeup',
                'c9': 'Talking to passenger'}

"""Demo Image Paths:

1.   c0 - img_9605.jpg - Safe
2.   c5 - img_6689.jpg - Operating Radio
3. c6 - img_9263.jpg - Drinking
4. c8 - img_9459.jpg - Hair
5. c7 - img_5241.jpg - Reaching Behind


"""

plt.figure(figsize = (12, 20))
# image_count = 1
# BASE_PATH = '/content/drive/MyDrive/Major Project/distracted_drivers_dataset/imgs/test'
BASE_PATH = '/content/drive/MyDrive/Major Project/naitik_using_phone_new.jpeg'
directory = 'c7'
file_name = 'img_5241.jpg'
# IMG_PATH = BASE_PATH + '/' + directory + '/' + file_name
IMG_PATH = BASE_PATH
fig = plt.subplot(5, 2, 1)
# image_count += 1
image = mpimg.imread(IMG_PATH)
plt.imshow(image)
# plt.title(activity_map[directory])

x_test_new = []
img_demo = get_cv2_image(IMG_PATH, 64, 64, 1)
x_test_new.append(img_demo)
x_test_new = np.array(x_test_new, dtype=np.uint8).reshape(-1,img_rows,img_cols,color_type)

model = tf.keras.models.load_model(MODEL_PATH)

pred = model.predict(x_test_new)

print("Predicted Class:", activity_map['c' + str(np.argmax(pred))])

model_testing = create_model_v2()

# More details about the layers
model_testing.summary()

# Compiling the model
model_testing.compile(optimizer='rmsprop', loss='categorical_crossentropy', metrics=['accuracy'])

